{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: Modeling: Introduction to K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# supress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Goals:\n",
    " - #### Cement a basic understanding of how K-Means operates\n",
    " - #### Observe an initial implementation of K-Means clustering\n",
    " - #### Learn how we can determine how many clusters to fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "> ### So What *is* K-Means Clustering?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering is the first unsupervised algorithm that we will implement.\n",
    "- **Remember**, when we say unsupervised in relation to machine learning, we are describing a methodology that does *not* have a labeled target.  This doesn't mean that we won't leverage our clusters for a supervised methodology, but that this type of algorithm cannot map to a specific label, only convey how things are similar based on the paremeters of whatever algorithm we use.\n",
    "- K-Means is a method of clustering that uses a pre-determined number of clusters \n",
    "- K stands for the number of clusters, similar to the way it means the number of neighbors in KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### So How does K-Means Clustering Work?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:  Randomly(ish) **choose k starting centers**\n",
    "\n",
    "Step 2: Use distance calculations to **assign every point to the cluster of whatever centroid each point is closest to**\n",
    "     \n",
    "Step 3: **Reposition the centroids** by calculating the mean of each dimension of the collective points that have been assigned to each cluster.\n",
    "\n",
    "Step 4+: **Iterate.** Now that we have moved centroids, re-assign your points and repeat the process, until the centers stop moving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual examples: \n",
    "\n",
    "K-means visuals (Slideshow): \n",
    "https://docs.google.com/presentation/d/1NtMLd4fp2pi_bDJiIg2O-5g48xJiXjtYFad42B6Pj6Q/edit?usp=sharing\n",
    "\n",
    "Animation (Thanks Zach!): https://stats-demos.zach.wiki/static/kmeans_clustering.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> #### Cool, let's check out how to use this in SKLearn!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "# import data\n",
    "\n",
    "iris = data('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
    "       'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define independent variables for k-means\n",
    "\n",
    "X = ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at distribution of sepal length and petal_length\n",
    "\n",
    "# ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X), columns= X.columns).set_index([X.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the head\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn implementation of KMeans\n",
    "\n",
    "#define the thing\n",
    "kmeans = \n",
    "\n",
    "# fit the thing\n",
    "####\n",
    "\n",
    "# Use (predict using) the thing \n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column names cluster in iris and X_scaled dataframe\n",
    "\n",
    "iris['cluster'] = kmeans.predict(X_scaled)\n",
    "\n",
    "X_scaled['cluster'] = kmeans.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at sample of 15 randomly selected rows in iris dataset\n",
    "\n",
    "iris.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in iris.groupby('cluster'):\n",
    "    plt.scatter(subset.sepal_length, subset.petal_length, label='cluster ' + str(cluster), alpha=.6, cmap='reds')\n",
    "plt.legend()\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('petal_length')\n",
    "plt.title('Visualizing Clusters')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 9))\n",
    "for cluster, subset in iris.groupby('species'):\n",
    "    plt.scatter(subset.sepal_length, subset.petal_length, label=str(cluster), alpha=.6)\n",
    "# centroids.plot.scatter(y='petal_length', x='sepal_length', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('petal_length')\n",
    "plt.title('Visualizing Species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes for Kmeans : \n",
    "\n",
    "- cluster_centers_: The center point of each cluster (aka centroids).\n",
    "\n",
    "- labels_: The labels for each observation.\n",
    "\n",
    "- inertia_: Sum of squared distances of samples to their closest cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Centers aka centroids. The output is scaled!!\n",
    "\n",
    "# kmeans.####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe \n",
    "centroids_scaled = pd.DataFrame(kmeans.cluster_centers_, columns = X.columns)\n",
    "centroids_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centriods for unscaled data?\n",
    "centroids = iris.groupby('cluster')['sepal_length', 'petal_length'].mean()\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to get unscaled centroids?\n",
    "\n",
    "#  ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels (same as from predict)\n",
    "\n",
    "# kmeans.####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in iris.groupby('cluster'):\n",
    "    plt.scatter(subset.sepal_length, subset.petal_length, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "# centroids.plot.scatter(y='petal_length', x='sepal_length', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('petal_length')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> ## Mini Exercise:\n",
    "\n",
    "> #### What if we chose a different number of clusters?\n",
    "\n",
    "> Take ten minutes to look through the documentation for K-Means Clustering on Sci-Kit Learn.\n",
    "\n",
    "> Change the number k of clusters, and then one other hyperparameter. Record your takeaways.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> #### How do we determine which K to use?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose 'k'\n",
    "\n",
    "#### The human element: Domain knowledge, intuition and prior knowledge\n",
    " - Do you have an understanding for how many markets might exist?\n",
    " - Do you have knowledge of some grouping that isnt referenced in your existing features?\n",
    " - Did you observe specific observable clusters in your exploratory data analysis?\n",
    "\n",
    "#### The computational element: Elbow Method\n",
    " - Try different k values and evaluate results\n",
    " - Inertia is a term that describes the sum of squared distances from each point to it's assigned centroid  \n",
    " - Inertia asymptotically approaches zero as we increase k.\n",
    " - We can observe a point where the interia begins to reduce less significantly, \"the elbow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can observe interia as a baked in property of our kmeans object\n",
    "kmeans.####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[['petal_length', 'sepal_length']]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X), columns= X.columns).set_index([X.index.values])\n",
    "\n",
    "k =2 \n",
    "\n",
    "kmeans = KMeans(n_clusters= k)\n",
    "kmeans.fit(X_scaled)\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# intertia with k = 3\n",
    "k =3\n",
    "\n",
    "kmeans = KMeans(n_clusters= k)\n",
    "kmeans.fit(X_scaled)\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# interia with k = 4\n",
    "\n",
    "k =4\n",
    "\n",
    "kmeans = KMeans(n_clusters= k)\n",
    "kmeans.fit(X_scaled)\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What value of k is appropriate?\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(13, 13), sharex=True, sharey=True)\n",
    "\n",
    "for ax, k in zip(axs.ravel(), range(2, 6)):\n",
    "    clusters = KMeans(k).fit(X_scaled).predict(X_scaled)\n",
    "    ax.scatter(X.sepal_length, X.petal_length, c=clusters)\n",
    "    ax.set(title='k = {}'.format(k), xlabel='sepal length', ylabel='petal length')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
